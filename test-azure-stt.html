<!DOCTYPE html>
<html>
<head>
    <title>Azure STT Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .form-group {
            margin-bottom: 20px;
        }
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
        }
        input[type="text"], input[type="password"] {
            width: 100%;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 14px;
        }
        button {
            background: #0078d4;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
            margin-right: 10px;
        }
        button:hover {
            background: #106ebe;
        }
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        .status {
            margin-top: 20px;
            padding: 15px;
            border-radius: 4px;
        }
        .status.success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        .status.info {
            background: #d1ecf1;
            color: #0c5460;
            border: 1px solid #bee5eb;
        }
        .transcript {
            margin-top: 20px;
            padding: 15px;
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 4px;
            min-height: 100px;
        }
        .controls {
            margin: 20px 0;
        }
        .recording {
            background: #dc3545 !important;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Azure Speech-to-Text Test</h1>
        <p>This page helps you test your Azure STT configuration before using it in the Agent Assist extension.</p>
        
        <div class="form-group">
            <label for="region">Azure Region:</label>
            <input type="text" id="region" placeholder="eastus, westus, etc.">
        </div>
        
        <div class="form-group">
            <label for="apiKey">API Key:</label>
            <input type="password" id="apiKey" placeholder="Your Azure Speech Service key">
        </div>
        
        <div class="controls">
            <button id="testConfig">Test Configuration</button>
            <button id="startRecording" disabled>Start Recording</button>
            <button id="stopRecording" disabled>Stop Recording</button>
        </div>
        
        <div id="status" class="status info" style="display: none;"></div>
        
        <div class="transcript">
            <h3>Transcription Results:</h3>
            <div id="transcriptText">Click "Start Recording" to begin...</div>
        </div>
        
        <div style="margin-top: 30px;">
            <h3>Instructions:</h3>
            <ol>
                <li>Enter your Azure region and API key</li>
                <li>Click "Test Configuration" to verify your credentials</li>
                <li>If successful, click "Start Recording" to test transcription</li>
                <li>Speak clearly into your microphone</li>
                <li>Click "Stop Recording" when done</li>
            </ol>
            
            <h3>Getting Azure Speech Service:</h3>
            <ol>
                <li>Go to <a href="https://portal.azure.com" target="_blank">Azure Portal</a></li>
                <li>Create a new "Speech Service" resource</li>
                <li>Note your region and copy the API key</li>
                <li>Use these credentials in the Agent Assist extension</li>
            </ol>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;

        // Load saved configuration
        chrome.storage.sync.get(['azureSttRegion', 'azureSttApiKey'], function(result) {
            if (result.azureSttRegion) {
                document.getElementById('region').value = result.azureSttRegion;
            }
            if (result.azureSttApiKey) {
                document.getElementById('apiKey').value = result.azureSttApiKey;
            }
        });

        function showStatus(message, type = 'info') {
            const status = document.getElementById('status');
            status.textContent = message;
            status.className = `status ${type}`;
            status.style.display = 'block';
        }

        function floatToWavBlob(float32, sampleRate) {
            // Convert to 16-bit PCM and wrap WAV header
            const pcm16 = new Int16Array(float32.length);
            for (let i = 0; i < float32.length; i++) {
                let s = Math.max(-1, Math.min(1, float32[i]));
                pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            
            const bytesPerSample = 2;
            const blockAlign = 1 * bytesPerSample;
            const byteRate = sampleRate * blockAlign;
            const buffer = new ArrayBuffer(44 + pcm16.length * bytesPerSample);
            const view = new DataView(buffer);
            let offset = 0;
            
            const writeStr = (s) => {
                for (let i = 0; i < s.length; i++) {
                    view.setUint8(offset++, s.charCodeAt(i));
                }
            };
            
            writeStr('RIFF');
            view.setUint32(offset, 36 + pcm16.length * bytesPerSample, true);
            offset += 4;
            writeStr('WAVE');
            writeStr('fmt ');
            view.setUint32(offset, 16, true);
            offset += 4;
            view.setUint16(offset, 1, true);
            offset += 2;
            view.setUint16(offset, 1, true);
            offset += 2;
            view.setUint32(offset, sampleRate, true);
            offset += 4;
            view.setUint32(offset, byteRate, true);
            offset += 4;
            view.setUint16(offset, blockAlign, true);
            offset += 2;
            view.setUint16(offset, 16, true);
            offset += 2;
            writeStr('data');
            view.setUint32(offset, pcm16.length * bytesPerSample, true);
            offset += 4;
            for (let i = 0; i < pcm16.length; i++, offset += 2) {
                view.setInt16(offset, pcm16[i], true);
            }
            return new Blob([buffer], { type: 'audio/wav' });
        }

        async function testAzureSTT(audioBlob, region, apiKey) {
            const endpoint = `https://${region}.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1`;
            const url = new URL(endpoint);
            url.searchParams.append('language', 'en-US');
            url.searchParams.append('format', 'detailed');
            url.searchParams.append('profanityFilter', 'None');
            url.searchParams.append('enableWordLevelTimestamps', 'true');

            try {
                const response = await fetch(url.toString(), {
                    method: 'POST',
                    headers: {
                        'Ocp-Apim-Subscription-Key': apiKey,
                        'Content-Type': 'audio/wav',
                        'Accept': 'application/json'
                    },
                    body: audioBlob
                });

                if (!response.ok) {
                    throw new Error(`Azure STT error: ${response.status} ${response.statusText}`);
                }

                const json = await response.json();
                console.log('Azure STT response:', json);

                let text = '';
                if (json.DisplayText) {
                    text = json.DisplayText;
                } else if (json.NBest && json.NBest.length > 0) {
                    text = json.NBest[0].Display || json.NBest[0].Lexical;
                } else if (json.Text) {
                    text = json.Text;
                }

                return text.trim();
            } catch (error) {
                throw error;
            }
        }

        document.getElementById('testConfig').addEventListener('click', async function() {
            const region = document.getElementById('region').value.trim();
            const apiKey = document.getElementById('apiKey').value.trim();

            if (!region || !apiKey) {
                showStatus('Please enter both region and API key.', 'error');
                return;
            }

            showStatus('Testing Azure STT configuration...', 'info');

            try {
                // Create a simple test audio (silence)
                const testAudio = new Float32Array(16000); // 1 second of silence at 16kHz
                const testBlob = floatToWavBlob(testAudio, 16000);
                
                await testAzureSTT(testBlob, region, apiKey);
                
                showStatus('âœ… Azure STT configuration is working! You can now use the extension.', 'success');
                document.getElementById('startRecording').disabled = false;
                
                // Save configuration
                chrome.storage.sync.set({
                    azureSttRegion: region,
                    azureSttApiKey: apiKey
                });
                
            } catch (error) {
                showStatus(`âŒ Configuration test failed: ${error.message}`, 'error');
                console.error('Azure STT test error:', error);
            }
        });

        document.getElementById('startRecording').addEventListener('click', async function() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });

                audioChunks = [];
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async function() {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    
                    // Convert to WAV format for Azure STT
                    const audioContext = new AudioContext();
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    const float32 = audioBuffer.getChannelData(0);
                    
                    // Downsample to 16kHz if needed
                    let sampleRate = audioBuffer.sampleRate;
                    let processedFloat32 = float32;
                    if (sampleRate !== 16000) {
                        const ratio = sampleRate / 16000;
                        const outLength = Math.floor(float32.length / ratio);
                        processedFloat32 = new Float32Array(outLength);
                        for (let i = 0; i < outLength; i++) {
                            processedFloat32[i] = float32[Math.floor(i * ratio)] || 0;
                        }
                        sampleRate = 16000;
                    }
                    
                    const wavBlob = floatToWavBlob(processedFloat32, sampleRate);
                    
                    showStatus('Processing audio with Azure STT...', 'info');
                    
                    try {
                        const region = document.getElementById('region').value.trim();
                        const apiKey = document.getElementById('apiKey').value.trim();
                        const transcript = await testAzureSTT(wavBlob, region, apiKey);
                        
                        if (transcript) {
                            document.getElementById('transcriptText').textContent = transcript;
                            showStatus('âœ… Transcription completed successfully!', 'success');
                        } else {
                            document.getElementById('transcriptText').textContent = 'No speech detected. Please try speaking more clearly.';
                            showStatus('âš ï¸ No speech detected in the recording.', 'info');
                        }
                    } catch (error) {
                        showStatus(`âŒ Transcription failed: ${error.message}`, 'error');
                        console.error('Transcription error:', error);
                    }
                };

                mediaRecorder.start();
                isRecording = true;
                this.textContent = 'Recording...';
                this.classList.add('recording');
                document.getElementById('stopRecording').disabled = false;
                showStatus('ðŸŽ¤ Recording... Speak now!', 'info');
                
            } catch (error) {
                showStatus(`âŒ Failed to start recording: ${error.message}`, 'error');
                console.error('Recording error:', error);
            }
        });

        document.getElementById('stopRecording').addEventListener('click', function() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                isRecording = false;
                this.textContent = 'Stop Recording';
                this.disabled = true;
                document.getElementById('startRecording').textContent = 'Start Recording';
                document.getElementById('startRecording').classList.remove('recording');
                showStatus('Processing audio...', 'info');
            }
        });
    </script>
</body>
</html>
